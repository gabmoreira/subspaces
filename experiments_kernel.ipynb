{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "jet = cm.get_cmap('jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708878d9",
   "metadata": {},
   "source": [
    "# Optimization for some chosen Y (no l2 normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba98bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "Y = torch.tensor([[1,0,0,0,0],\n",
    "                  [1,1,1,1,0],\n",
    "                  [0,0,1,1,0],\n",
    "                  [0,1,0,1,0],\n",
    "                  [0,0,0,1,1]])\n",
    "Y = torch.unique(Y, dim=-1)\n",
    "Y = Y.repeat_interleave(torch.randint(15, 35, size=(Y.shape[-1],)), dim=1)\n",
    "\n",
    "u, labels = torch.unique(Y, dim=-1, return_inverse=True)\n",
    "labels = labels / labels.max()\n",
    "\n",
    "c, n = Y.shape\n",
    "\n",
    "X = torch.normal(0, 0.1, size=(8, n), requires_grad=True)\n",
    "norm = torch.ones(size=(n,), requires_grad=True)\n",
    "tau = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "alpha = 0.9\n",
    "beta  = 0.01\n",
    "niter = 2000\n",
    "\n",
    "tracker = {'loss' : [], 'x_svals' : []}\n",
    "bar = tqdm(total=niter, dynamic_ncols=True, desc='Train')\n",
    "\n",
    "optimizer = optim.SGD([X, norm, tau], lr=0.01, momentum=0.98)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.9995)\n",
    "X = X.to(device)\n",
    "Y = Y.to(device)\n",
    "norm = norm.to(device)\n",
    "\n",
    "for i in range(niter):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    idx = np.random.choice(np.arange(n), 70, replace=False)\n",
    "\n",
    "    norm_batch = norm[idx]\n",
    "    y_batch = Y[:,idx].float()\n",
    "    x_batch = X[:,idx]\n",
    "    \n",
    "    Kx = norm_batch.reshape(-1,1) * torch.exp(-(torch.cdist(x_batch.T, x_batch.T, p=2)**2) / tau) * norm_batch.reshape(1,-1)\n",
    "    #Kx = X[:,idx].T @ X[:,idx]\n",
    "\n",
    "    _, _, y_batch = torch.linalg.svd(y_batch)\n",
    "    y_batch = F.normalize(y_batch[:5,:], dim=0, p=2)\n",
    "    Ky = (y_batch.T @ y_batch).float()\n",
    "\n",
    "    z_svals = torch.sqrt(F.relu(torch.linalg.eigvalsh(Ky + Kx)))\n",
    "    x_svals = torch.sqrt(F.relu(torch.linalg.eigvalsh(Kx)))\n",
    "    z_nuc = z_svals.sum()\n",
    "    x_nuc = x_svals.sum()\n",
    "\n",
    "    loss = z_nuc - alpha * x_nuc + beta * x_svals.max() ** 2\n",
    "    loss.backward()\n",
    "    tracker['loss'].append(loss.detach().item())\n",
    "    tracker['x_svals'].append(x_svals.detach().sort()[0])\n",
    "\n",
    "    bar.set_postfix(loss=\"{:1.5e}\".format(loss.detach().item()),\n",
    "                    grad=\"{:1.3e}\".format(torch.linalg.norm(X.grad, 'fro')),\n",
    "                    tau=\"{:1.3e}\".format(tau.detach()),\n",
    "                    lr=\"{:1.3e}\".format(scheduler.get_last_lr()[0]))\n",
    "    bar.update()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a454c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ = Y.detach().cpu()\n",
    "X_ = X.detach().cpu()\n",
    "#K_ = (F.normalize(X_, p=2, dim=0).T @ F.normalize(X_, p=2, dim=0)) ** 2\n",
    "K_ = torch.exp(-(torch.cdist(X_.T, X_.T, p=2)**2) / 1.0)\n",
    "svals_ = torch.stack(tracker['x_svals'], dim=0).detach().cpu()\n",
    "Z_ = torch.cat((Y_,X_), dim=0)\n",
    "\n",
    "fig = plt.figure(figsize=(30,5))\n",
    "plt.subplot(1,5,1)\n",
    "plt.imshow(Y_)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Y {Y_.shape[0]}x{Y_.shape[1]} ({u.shape[1]} minterms)\")\n",
    "plt.subplot(1,5,2)\n",
    "for j in range(svals_.shape[1]):\n",
    "    plt.plot(svals_[::5,j], '-', linewidth=1.0)\n",
    "plt.title(\"\\sqrt{\\lambda_i(K)}\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.subplot(1,5,3)\n",
    "sns.heatmap(K_)\n",
    "plt.colorbar(fraction=0.05, pad=0.04)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Kernel\")\n",
    "plt.subplot(1,5,4)\n",
    "plt.plot(tracker[\"loss\"])\n",
    "plt.xscale(\"log\")\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade40d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.linalg import eigh, norm\n",
    "\n",
    "idx = torch.where(Y[0,:] == 1)[0]\n",
    "\n",
    "# Build kernel matrix for representations verifying proposition\n",
    "subspace_vecs = X[idx]\n",
    "subspace_kernel = torch.exp(-(torch.cdist(subspace_vecs, subspace_vecs, p=2)**2) / tau)\n",
    "\n",
    "subspace_lambdas, subspace_evecs = eigh(subspace_kernel)\n",
    "\n",
    "lambdas_mask = subspace_lambdas > 1e-1\n",
    "lambdas = subspace_lambdas[lambdas_mask]\n",
    "subspace_evecs = subspace_evecs[:,lambdas_mask]\n",
    "subspace_evecs /= norm(subspace_evecs, ord=2, dim=0)\n",
    "subspace_evecs /= torch.sqrt(lambdas.view(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da9d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "subspace_evecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11afa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_memory_query = torch.exp(-(torch.cdist(subspace_vecs, X, p=2)**2) / tau) \n",
    "\n",
    "subspace_projections = torch.einsum(\"ij,ik->jk\", kernel_memory_query, subspace_evecs)\n",
    "prob = torch.square(subspace_projections).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf42f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subspace_evecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfe9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "mu = torch.linalg.svdvals(Y)\n",
    "print(mu)\n",
    "def curve(x):\n",
    "    x = x[0]\n",
    "    return [np.array([x / np.sqrt(m**2 + x**2) for m in mu]).sum() - len(mu)*alpha + 2.0 * beta * x]\n",
    "\n",
    "def grad(x):\n",
    "    x = x[0]\n",
    "    return [np.array([m**2 / np.sqrt(m**2 + x**2)**3 for m in mu]).sum() + 2.0 * beta]\n",
    "\n",
    "sol = optimize.root(curve, [0.0], jac=grad, method='hybr')\n",
    "print(\"Singular values according to theory: {}\".format(round(sol.x[0], 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb262b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.stem(svals_[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

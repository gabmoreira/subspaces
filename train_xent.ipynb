{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torchtnt.utils.device import copy_data_to_device\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "jet = cm.get_cmap('jet')\n",
    "\n",
    "from resnet import *\n",
    "from convnet import *\n",
    "from dataset import *\n",
    "\n",
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(\n",
    "    dataset=\"CIFAR100\",\n",
    "    split=\"train\",\n",
    "    img_size=40,\n",
    "    batch_size=512,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "    \n",
    "val_loader = get_loader(\n",
    "    dataset=\"CIFAR100\",\n",
    "    split=\"val\",\n",
    "    img_size=40,\n",
    "    batch_size=512,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b91d78",
   "metadata": {},
   "source": [
    "# Xent configs\n",
    "\n",
    "- MNIST ConvNet:  Adam@1e-2, max_epochs=20, StepLR(optimizer, 1, 0.7) **VAL ACC = 0.992**\n",
    "\n",
    "- MNIST ResNet18: Adam@1e-2, max_epochs=20, StepLR(optimizer, 1, 0.7)  **VAL ACC = 0.995**\n",
    "\n",
    "- FashionMNIST ConvNet:  Adam@1e-2, max_epochs=50, StepLR(optimizer, 4, 0.5) **VAL ACC = 0.930**\n",
    "\n",
    "- FashionMNIST ResNet18: Adam@1e-2, max_epochs=50, StepLR(optimizer, 4, 0.5) **VAL ACC = 0.935**\n",
    "\n",
    "- CIFAR10 ResNet18: SGD@1e-1, momentum=0.9, max_epochs=200, CosineAnnealingLR(T_max=200) **VAL ACC = 0.929**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd4231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = resnet18(in_dim=3, out_dim=100, activation=torch.nn.functional.leaky_relu)\n",
    "#module = ConvNet(in_dim=1, out_dim=10, activation=torch.nn.functional.leaky_relu)\n",
    "module = module.to(device)\n",
    "\n",
    "max_epochs = 200\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    module.parameters(),\n",
    "    lr=1e-1,\n",
    "    momentum=0.9,\n",
    ")\n",
    "\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=200)\n",
    "#lr_scheduler = StepLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    module.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = copy_data_to_device(batch, device=device)\n",
    "        logits = module(batch.images)\n",
    "        loss = F.cross_entropy(logits,\n",
    "                               torch.argmax(batch.labels, dim=-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    module.eval()\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    for batch in val_loader:\n",
    "        batch = copy_data_to_device(batch, device=device)\n",
    "        logits = module(batch.images)\n",
    "        pred_idx = torch.argmax(logits, dim=-1)\n",
    "        target_idx = torch.argmax(batch.labels, dim=-1)\n",
    "        num_correct += (pred_idx == target_idx).sum()\n",
    "        total += len(pred_idx)\n",
    "\n",
    "    print(f\"Epoch {epoch} val acc: {num_correct / total} | lr = {lr_scheduler.get_last_lr()[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
